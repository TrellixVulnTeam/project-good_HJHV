{"ast":null,"code":"import { FILE_STATES, logger } from \"@rpldy/shared\";\nimport processBatchItems from \"./processBatchItems\";\nimport { getBatchDataFromItemId, getIsItemBatchReady, isNewBatchStarting, cancelBatchForItem, loadNewBatchForItem, isItemBelongsToBatch } from \"./batchHelpers\";\n\nconst getIsItemInActiveRequest = (queue, itemId) => {\n  return !!~queue.getState().activeIds // $FlowFixMe - no flat\n  .flat().indexOf(itemId);\n};\n\nconst getIsItemReady = item => item.state === FILE_STATES.ADDED;\n\nexport const findNextItemIndex = queue => {\n  const state = queue.getState(),\n        itemQueue = state.itemQueue,\n        items = state.items;\n  let index = 0,\n      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a \"ready\" batch\n\n  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !getIsItemBatchReady(queue, nextId) || !getIsItemReady(items[nextId]))) {\n    index += 1;\n    nextId = itemQueue[index];\n  }\n\n  return nextId ? index : -1;\n};\nexport const getNextIdGroup = queue => {\n  const itemQueue = queue.getState().itemQueue;\n  const nextItemIndex = findNextItemIndex(queue);\n  let nextId = itemQueue[nextItemIndex],\n      nextGroup;\n\n  if (nextId) {\n    const batchData = getBatchDataFromItemId(queue, nextId);\n    const batchId = batchData.batch.id,\n          groupMax = batchData.batchOptions.maxGroupSize || 0;\n\n    if (batchData.batchOptions.grouped && groupMax > 1) {\n      nextGroup = [];\n      let nextBelongsToSameBatch = true; //dont group files from different batches\n\n      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {\n        nextGroup.push(nextId);\n        nextId = itemQueue[nextItemIndex + nextGroup.length];\n        nextBelongsToSameBatch = nextId && isItemBelongsToBatch(queue, nextId, batchId);\n      }\n    } else {\n      nextGroup = [nextId];\n    }\n  }\n\n  return nextGroup;\n};\n\nconst processNext = queue => {\n  const ids = getNextIdGroup(queue);\n  let resultP = Promise.resolve();\n\n  if (ids) {\n    const currentCount = queue.getCurrentActiveCount(),\n          {\n      concurrent = 0,\n      maxConcurrent = 0\n    } = queue.getOptions();\n\n    if (!currentCount || concurrent && currentCount < maxConcurrent) {\n      logger.debugLog(\"uploader.processor: Processing next upload - \", {\n        ids,\n        state: queue.getState(),\n        currentCount\n      });\n      let cancelled = false;\n      let newBatchP = Promise.resolve(false);\n\n      if (isNewBatchStarting(queue, ids[0])) {\n        newBatchP = loadNewBatchForItem(queue, ids[0]).then(allowBatch => {\n          cancelled = !allowBatch;\n\n          if (cancelled) {\n            cancelBatchForItem(queue, ids[0]);\n            processNext(queue);\n          }\n\n          return cancelled;\n        });\n      }\n\n      resultP = newBatchP.then(cancelled => {\n        if (!cancelled) {\n          processBatchItems(queue, ids, processNext);\n        }\n      });\n    }\n  }\n\n  return resultP;\n};\n\nexport default processNext;","map":{"version":3,"sources":["C:/Users/USER/Documents/GitHub/project-good/project/client/node_modules/@rpldy/uploader/lib/esm/queue/processQueueNext.js"],"names":["FILE_STATES","logger","processBatchItems","getBatchDataFromItemId","getIsItemBatchReady","isNewBatchStarting","cancelBatchForItem","loadNewBatchForItem","isItemBelongsToBatch","getIsItemInActiveRequest","queue","itemId","getState","activeIds","flat","indexOf","getIsItemReady","item","state","ADDED","findNextItemIndex","itemQueue","items","index","nextId","getNextIdGroup","nextItemIndex","nextGroup","batchData","batchId","batch","id","groupMax","batchOptions","maxGroupSize","grouped","nextBelongsToSameBatch","length","push","processNext","ids","resultP","Promise","resolve","currentCount","getCurrentActiveCount","concurrent","maxConcurrent","getOptions","debugLog","cancelled","newBatchP","then","allowBatch"],"mappings":"AAAA,SAASA,WAAT,EAAsBC,MAAtB,QAAoC,eAApC;AACA,OAAOC,iBAAP,MAA8B,qBAA9B;AACA,SAASC,sBAAT,EAAiCC,mBAAjC,EAAsDC,kBAAtD,EAA0EC,kBAA1E,EAA8FC,mBAA9F,EAAmHC,oBAAnH,QAA+I,gBAA/I;;AAEA,MAAMC,wBAAwB,GAAG,CAACC,KAAD,EAAQC,MAAR,KAAmB;AAClD,SAAO,CAAC,CAAC,CAACD,KAAK,CAACE,QAAN,GAAiBC,SAAjB,CAA2B;AAA3B,GACTC,IADS,GACFC,OADE,CACMJ,MADN,CAAV;AAED,CAHD;;AAKA,MAAMK,cAAc,GAAGC,IAAI,IAAIA,IAAI,CAACC,KAAL,KAAelB,WAAW,CAACmB,KAA1D;;AAEA,OAAO,MAAMC,iBAAiB,GAAGV,KAAK,IAAI;AACxC,QAAMQ,KAAK,GAAGR,KAAK,CAACE,QAAN,EAAd;AAAA,QACMS,SAAS,GAAGH,KAAK,CAACG,SADxB;AAAA,QAEMC,KAAK,GAAGJ,KAAK,CAACI,KAFpB;AAGA,MAAIC,KAAK,GAAG,CAAZ;AAAA,MACIC,MAAM,GAAGH,SAAS,CAACE,KAAD,CADtB,CAJwC,CAKT;;AAE/B,SAAOC,MAAM,KAAKf,wBAAwB,CAACC,KAAD,EAAQc,MAAR,CAAxB,IAA2C,CAACpB,mBAAmB,CAACM,KAAD,EAAQc,MAAR,CAA/D,IAAkF,CAACR,cAAc,CAACM,KAAK,CAACE,MAAD,CAAN,CAAtG,CAAb,EAAqI;AACnID,IAAAA,KAAK,IAAI,CAAT;AACAC,IAAAA,MAAM,GAAGH,SAAS,CAACE,KAAD,CAAlB;AACD;;AAED,SAAOC,MAAM,GAAGD,KAAH,GAAW,CAAC,CAAzB;AACD,CAbM;AAcP,OAAO,MAAME,cAAc,GAAGf,KAAK,IAAI;AACrC,QAAMW,SAAS,GAAGX,KAAK,CAACE,QAAN,GAAiBS,SAAnC;AACA,QAAMK,aAAa,GAAGN,iBAAiB,CAACV,KAAD,CAAvC;AACA,MAAIc,MAAM,GAAGH,SAAS,CAACK,aAAD,CAAtB;AAAA,MACIC,SADJ;;AAGA,MAAIH,MAAJ,EAAY;AACV,UAAMI,SAAS,GAAGzB,sBAAsB,CAACO,KAAD,EAAQc,MAAR,CAAxC;AACA,UAAMK,OAAO,GAAGD,SAAS,CAACE,KAAV,CAAgBC,EAAhC;AAAA,UACMC,QAAQ,GAAGJ,SAAS,CAACK,YAAV,CAAuBC,YAAvB,IAAuC,CADxD;;AAGA,QAAIN,SAAS,CAACK,YAAV,CAAuBE,OAAvB,IAAkCH,QAAQ,GAAG,CAAjD,EAAoD;AAClDL,MAAAA,SAAS,GAAG,EAAZ;AACA,UAAIS,sBAAsB,GAAG,IAA7B,CAFkD,CAEf;;AAEnC,aAAOT,SAAS,CAACU,MAAV,GAAmBL,QAAnB,IAA+BI,sBAAtC,EAA8D;AAC5DT,QAAAA,SAAS,CAACW,IAAV,CAAed,MAAf;AACAA,QAAAA,MAAM,GAAGH,SAAS,CAACK,aAAa,GAAGC,SAAS,CAACU,MAA3B,CAAlB;AACAD,QAAAA,sBAAsB,GAAGZ,MAAM,IAAIhB,oBAAoB,CAACE,KAAD,EAAQc,MAAR,EAAgBK,OAAhB,CAAvD;AACD;AACF,KATD,MASO;AACLF,MAAAA,SAAS,GAAG,CAACH,MAAD,CAAZ;AACD;AACF;;AAED,SAAOG,SAAP;AACD,CA1BM;;AA4BP,MAAMY,WAAW,GAAG7B,KAAK,IAAI;AAC3B,QAAM8B,GAAG,GAAGf,cAAc,CAACf,KAAD,CAA1B;AACA,MAAI+B,OAAO,GAAGC,OAAO,CAACC,OAAR,EAAd;;AAEA,MAAIH,GAAJ,EAAS;AACP,UAAMI,YAAY,GAAGlC,KAAK,CAACmC,qBAAN,EAArB;AAAA,UACM;AACJC,MAAAA,UAAU,GAAG,CADT;AAEJC,MAAAA,aAAa,GAAG;AAFZ,QAGFrC,KAAK,CAACsC,UAAN,EAJJ;;AAMA,QAAI,CAACJ,YAAD,IAAiBE,UAAU,IAAIF,YAAY,GAAGG,aAAlD,EAAiE;AAC/D9C,MAAAA,MAAM,CAACgD,QAAP,CAAgB,+CAAhB,EAAiE;AAC/DT,QAAAA,GAD+D;AAE/DtB,QAAAA,KAAK,EAAER,KAAK,CAACE,QAAN,EAFwD;AAG/DgC,QAAAA;AAH+D,OAAjE;AAKA,UAAIM,SAAS,GAAG,KAAhB;AACA,UAAIC,SAAS,GAAGT,OAAO,CAACC,OAAR,CAAgB,KAAhB,CAAhB;;AAEA,UAAItC,kBAAkB,CAACK,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAtB,EAAuC;AACrCW,QAAAA,SAAS,GAAG5C,mBAAmB,CAACG,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAnB,CAAmCY,IAAnC,CAAwCC,UAAU,IAAI;AAChEH,UAAAA,SAAS,GAAG,CAACG,UAAb;;AAEA,cAAIH,SAAJ,EAAe;AACb5C,YAAAA,kBAAkB,CAACI,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAlB;AACAD,YAAAA,WAAW,CAAC7B,KAAD,CAAX;AACD;;AAED,iBAAOwC,SAAP;AACD,SATW,CAAZ;AAUD;;AAEDT,MAAAA,OAAO,GAAGU,SAAS,CAACC,IAAV,CAAeF,SAAS,IAAI;AACpC,YAAI,CAACA,SAAL,EAAgB;AACdhD,UAAAA,iBAAiB,CAACQ,KAAD,EAAQ8B,GAAR,EAAaD,WAAb,CAAjB;AACD;AACF,OAJS,CAAV;AAKD;AACF;;AAED,SAAOE,OAAP;AACD,CA1CD;;AA4CA,eAAeF,WAAf","sourcesContent":["import { FILE_STATES, logger } from \"@rpldy/shared\";\nimport processBatchItems from \"./processBatchItems\";\nimport { getBatchDataFromItemId, getIsItemBatchReady, isNewBatchStarting, cancelBatchForItem, loadNewBatchForItem, isItemBelongsToBatch } from \"./batchHelpers\";\n\nconst getIsItemInActiveRequest = (queue, itemId) => {\n  return !!~queue.getState().activeIds // $FlowFixMe - no flat\n  .flat().indexOf(itemId);\n};\n\nconst getIsItemReady = item => item.state === FILE_STATES.ADDED;\n\nexport const findNextItemIndex = queue => {\n  const state = queue.getState(),\n        itemQueue = state.itemQueue,\n        items = state.items;\n  let index = 0,\n      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a \"ready\" batch\n\n  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !getIsItemBatchReady(queue, nextId) || !getIsItemReady(items[nextId]))) {\n    index += 1;\n    nextId = itemQueue[index];\n  }\n\n  return nextId ? index : -1;\n};\nexport const getNextIdGroup = queue => {\n  const itemQueue = queue.getState().itemQueue;\n  const nextItemIndex = findNextItemIndex(queue);\n  let nextId = itemQueue[nextItemIndex],\n      nextGroup;\n\n  if (nextId) {\n    const batchData = getBatchDataFromItemId(queue, nextId);\n    const batchId = batchData.batch.id,\n          groupMax = batchData.batchOptions.maxGroupSize || 0;\n\n    if (batchData.batchOptions.grouped && groupMax > 1) {\n      nextGroup = [];\n      let nextBelongsToSameBatch = true; //dont group files from different batches\n\n      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {\n        nextGroup.push(nextId);\n        nextId = itemQueue[nextItemIndex + nextGroup.length];\n        nextBelongsToSameBatch = nextId && isItemBelongsToBatch(queue, nextId, batchId);\n      }\n    } else {\n      nextGroup = [nextId];\n    }\n  }\n\n  return nextGroup;\n};\n\nconst processNext = queue => {\n  const ids = getNextIdGroup(queue);\n  let resultP = Promise.resolve();\n\n  if (ids) {\n    const currentCount = queue.getCurrentActiveCount(),\n          {\n      concurrent = 0,\n      maxConcurrent = 0\n    } = queue.getOptions();\n\n    if (!currentCount || concurrent && currentCount < maxConcurrent) {\n      logger.debugLog(\"uploader.processor: Processing next upload - \", {\n        ids,\n        state: queue.getState(),\n        currentCount\n      });\n      let cancelled = false;\n      let newBatchP = Promise.resolve(false);\n\n      if (isNewBatchStarting(queue, ids[0])) {\n        newBatchP = loadNewBatchForItem(queue, ids[0]).then(allowBatch => {\n          cancelled = !allowBatch;\n\n          if (cancelled) {\n            cancelBatchForItem(queue, ids[0]);\n            processNext(queue);\n          }\n\n          return cancelled;\n        });\n      }\n\n      resultP = newBatchP.then(cancelled => {\n        if (!cancelled) {\n          processBatchItems(queue, ids, processNext);\n        }\n      });\n    }\n  }\n\n  return resultP;\n};\n\nexport default processNext;"]},"metadata":{},"sourceType":"module"}